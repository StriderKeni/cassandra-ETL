{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/StriderKeni/Documents/Data_Science/Data_Engineering/Projects/cassandra-ETL\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    # the number below include header\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Modeling NoSQL Database\n",
    "\n",
    "## event_datafile_new.csv columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of the file <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cluster using local machine (127.0.0.1)\n",
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    # Creating a session variable to  establish connection and begin executing queries\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyspace for NoSQL database\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkifydb\n",
    "    WITH REPLICATION =\n",
    "    {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "## This allow to start using and executing queries to the keyspace\n",
    "try:\n",
    "    session.set_keyspace('sparkifydb')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries based on needs of the Analytic Team\n",
    "\n",
    " 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    " 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    " 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Model based on Queries Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table statement to be sure that is not created before. \n",
    "try:\n",
    "    session.execute('DROP TABLE IF EXISTS music_library_first')\n",
    "    session.execute('DROP TABLE IF EXISTS music_library_second')\n",
    "    session.execute('DROP TABLE IF EXISTS music_library_third')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Query\n",
    "\n",
    "- Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE statement for first table based on first query.\n",
    "query_1 = \"CREATE TABLE IF NOT EXISTS music_library_first\"\n",
    "query_1 = query_1 + \"(session_id int, item_session int, user_id int, first_name text, last_name text, artist text, song text, length decimal, PRIMARY KEY((session_id), item_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query_1)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal \n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "# Open the csv file with data and iterate into every row.\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Insert statement for first table\n",
    "        query = \"INSERT INTO music_library_first (session_id, item_session, user_id, first_name, last_name, artist, song, length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        # Execute insert iterating into every row of the CSV File\n",
    "        session.execute(query, (int(line[8]), int(line[3]), int(line[10]), line[1], line[4], line[0], line[9], Decimal(line[5])))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6820 rows inserted\n"
     ]
    }
   ],
   "source": [
    "## Select statement to verify if the data was inserted into the table\n",
    "try:\n",
    "    rows = session.execute(\"SELECT * FROM music_library_first\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(\"{} rows inserted\".format(len(list(rows))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "# Select First Query\n",
    "# Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "try:\n",
    "    results_1 = session.execute(\"SELECT artist, song, length FROM music_library_first \\\n",
    "    WHERE session_id = 338 and item_session = 4\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in results_1:\n",
    "    print(row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Query\n",
    "\n",
    "- Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATEMENT for second table based on second query.\n",
    "query_2 = \"CREATE TABLE IF NOT EXISTS music_library_second\"\n",
    "query_2 = query_2 + \"(user_id int, session_id int, item_session int, first_name text, last_name text, artist text, song text, PRIMARY KEY((user_id), session_id, item_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query_2)\n",
    "except Exception as e:\n",
    "    print(e)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into second table \n",
    "\n",
    "# Open the csv file with data and iterate into every row.\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # Insert statement for second table \n",
    "        query = \"INSERT INTO music_library_second (user_id, session_id, item_session, first_name, last_name, artist, song)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        # Execute insert iterating into every row of the CSV File\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[1], line[4], line[0], line[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz 10 182 0\n",
      "Three Drives Greece 2000 Sylvie Cruz 10 182 1\n",
      "Sebastien Tellier Kilometer Sylvie Cruz 10 182 2\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz 10 182 3\n"
     ]
    }
   ],
   "source": [
    "# SELECT for second query\n",
    "## Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "try:\n",
    "    results_2 = session.execute(\"SELECT artist, song, first_name, last_name, user_id, session_id, item_session \\\n",
    "    FROM music_library_second WHERE user_id = 10 and session_id = 182\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in results_2:\n",
    "    print(row.artist, row.song, row.first_name, row.last_name, row.user_id, row.session_id, row.item_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Query \n",
    "\n",
    "- Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATEMENT for third table based on third query.\n",
    "query_3 = \"CREATE TABLE music_library_third\"\n",
    "query_3 = query_3 + \"(song text, user_id int, first_name text, last_name text, artist text, PRIMARY KEY((song), user_id, first_name, last_name))\"\n",
    "\n",
    "# We are going to use SONG and USER_ID as Primary Key and Clustering Key, this will allow the database to update the values\n",
    "## which may be ok based on the statement of the query, because the team is asking about a list of users (name and last name)\n",
    "### and not about how many times that song was listened. That's why I decided to create the table in that order.\n",
    "#### I added some clustering columns like first_name and last_name to order the output data by name and last name\n",
    "try:\n",
    "    session.execute(query_3)\n",
    "except Exception as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert into third table \n",
    "\n",
    "# Open the csv file with data and iterate into every row.\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) #skip header\n",
    "    for line in csvreader:\n",
    "        # Insert statement \n",
    "        query = \"INSERT INTO music_library_third (song, user_id, first_name, last_name, artist)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        # Execute insert into third table\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4], line[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch All Hands Against His Own 29\n",
      "Tegan Levine All Hands Against His Own 80\n",
      "Sara Johnson All Hands Against His Own 95\n"
     ]
    }
   ],
   "source": [
    "# SELECT for third query\n",
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "try:\n",
    "    results_3 = session.execute(\"SELECT first_name, last_name, song, user_id FROM music_library_third \\\n",
    "    WHERE song = 'All Hands Against His Own'\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in results_3:\n",
    "    print(row.first_name, row.last_name, row.song, row.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop table statements\n",
    "try:\n",
    "    session.execute(\"DROP TABLE IF EXISTS music_library_first\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS music_library_second\")\n",
    "    session.execute(\"DROP TABLE IF EXISTS music_library_third\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
